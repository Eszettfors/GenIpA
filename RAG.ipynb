{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies and loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: /Users/hannes/Documents/Programming/GitHub/GenIpA/GenIpa/bin/pip: bad interpreter: /Users/hannes/Documents/Programming/GitHub/GenIpA/.conda/bin/python: no such file or directory\n",
      "zsh:1: /Users/hannes/Documents/Programming/GitHub/GenIpA/GenIpa/bin/pip: bad interpreter: /Users/hannes/Documents/Programming/GitHub/GenIpA/.conda/bin/python: no such file or directory\n",
      "zsh:1: /Users/hannes/Documents/Programming/GitHub/GenIpA/GenIpa/bin/pip: bad interpreter: /Users/hannes/Documents/Programming/GitHub/GenIpA/.conda/bin/python: no such file or directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#pip install -q openai\n",
    "#pip install -q llama-index\n",
    "#pip install -q llama-index-experimental\n",
    "#pip install -q pypdf\n",
    "#pip install -q docx2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-ati0Co2Vt8anHxAf9emxT3BlbkFJzBBqjuNyNos5W71ryVtc\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import glob\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "## Llamaindex readers\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "## LlamaIndex Index Types\n",
    "from llama_index.core import ListIndex\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import TreeIndex\n",
    "from llama_index.core import KeywordTableIndex\n",
    "from llama_index.core import SimpleKeywordTableIndex\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.core import KnowledgeGraphIndex\n",
    "from llama_index.experimental.query_engine import PandasQueryEngine\n",
    "\n",
    "## LlamaIndex Context Managers\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.schema import Node\n",
    "\n",
    "## LlamaIndex Callbacks\n",
    "from llama_index.core.callbacks import CallbackManager\n",
    "from llama_index.core.callbacks import LlamaDebugHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "model=\"gpt-3.5-turbo\"\n",
    "#model=\"gpt-4\"\n",
    "#model=\"gpt-4-turbo\"\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "Settings.llm = OpenAI(temperature=0, \n",
    "                      model=model, \n",
    "                      #max_tokens=512\n",
    "                      PRESENCE_PENALTY=-2,\n",
    "                      TOP_P=1,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current dir: /Users/hannes/Documents/Programming/GitHub/GenIpA\n",
      "Files in data/\n",
      ".DS_Store\n",
      "en_UK.txt\n",
      "sv.txt\n"
     ]
    }
   ],
   "source": [
    "DOCS_DIR = \"data/\"\n",
    "PERSIST_DIR = \"index/\"\n",
    "\n",
    "print(f\"Current dir: {os.getcwd()}\")\n",
    "\n",
    "if not os.path.exists(DOCS_DIR):\n",
    "  os.mkdir(DOCS_DIR)\n",
    "docs = os.listdir(DOCS_DIR)\n",
    "docs = [d for d in docs]\n",
    "docs.sort()\n",
    "print(f\"Files in {DOCS_DIR}\")\n",
    "for doc in docs:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "splitter = SentenceSplitter(chunk_size=2048)\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retrieve_index(index_path, docs_path, index_type):\n",
    "    if not os.path.exists(index_path):\n",
    "        print(f\"Creating Directory {index_path}\")\n",
    "        os.mkdir(index_path)\n",
    "    if os.listdir(index_path) == []:\n",
    "        print(\"Loading Documents...\")\n",
    "        documents = SimpleDirectoryReader(input_files=[f\"{docs_path}{'sv.txt'}\"]).load_data()\n",
    "        print(\"Creating Index...\")\n",
    "        index = index_type.from_documents(documents,\n",
    "                                          transformations=[splitter],\n",
    "                                          #response_synthesizer=response_synthesizer,\n",
    "                                          show_progress=True,\n",
    "                                          )\n",
    "        print(\"Persisting Index...\")\n",
    "        index.storage_context.persist(persist_dir=index_path)\n",
    "        print(\"Done!\")\n",
    "    else:\n",
    "        print(\"Reading from Index...\")\n",
    "        index = load_index_from_storage(storage_context=StorageContext.from_defaults(persist_dir=index_path))\n",
    "        print(\"Done!\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en_UK.txt', 'sv.txt', '.DS_Store']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(DOCS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vector store indexes for swedish dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Vector store indexes? Efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Documents...\n",
      "Creating Index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Generating embeddings: 100%|██████████| 235/235 [00:06<00:00, 35.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persisting Index...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "VECTORINDEXDIR = PERSIST_DIR + 'VectorStoreIndex'\n",
    "vectorstoreindex = create_retrieve_index(VECTORINDEXDIR, DOCS_DIR, VectorStoreIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating vector store indexes for UK dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from Index...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "VECTORINDEXDIR = PERSIST_DIR + 'VectorStoreIndex'\n",
    "vectorstoreindex = create_retrieve_index(VECTORINDEXDIR, DOCS_DIR, VectorStoreIndex, 'en_UK.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the vector base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vectorstoreindex.as_query_engine(retriever_mode=\"embedding\",\n",
    "                                                response_mode=\"compact\",\n",
    "                                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jɑːg bʊr ²'uːvɑːn dɪg iː ²hʉːsɛt/\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Please transcribe this text to IPA: 'Jag bor ovan dig i huset' using the indexes\" ) \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jaːg eːr ʊˈvɑn vɪd at ˈspeːla ˈfɔtbɔl/\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Transkribera denna text till IPA: 'Jag är ovan vid att spela fotboll'\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jɑː spelar f'ɔtːbɔl/\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Please transcribe this text to IPA: 'Jag spelar fotboll', ignoring your own knowledge\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/j'ɛstɛrdɛj aɪ w'ækst maɪ k'ɑːr/\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Please transcribe this text to IPA: 'yesterday I waxed my car', using the indexes\") \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    response = openai.chat.completions.create(model=model,\n",
    "                                              messages=messages,\n",
    "                                              temperature=temperature\n",
    "                                              \n",
    "                                              )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is the transcription of the text \"yesterday I read a book on water\" using the International Phonetic Alphabet (IPA):\n",
      "\n",
      "/jɛstərˈdeɪ aɪ rɛd ə bʊk ɒn ˈwɔtər/\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "\"Please transcribe this text to IPA using the indexes: yesterday I read a book on water\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt, temperature=0.5)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here is the transcription of the text \"yesterday I read a book on water\" in American English IPA:\n",
      "\n",
      "/jɛstɚdeɪ aɪ rɛd ə bʊk ɑn ˈwɔtər/\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "\"Please transcribe this text to IPA in american english: yesterday I read a book on water\"\n",
    "\"\"\"\n",
    "response = get_completion(prompt, temperature=0.5)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ɐ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mɐ\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ɐ' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
